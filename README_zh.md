# GLM-4.1V-Thinking

[Read this in English.](./README.md)

<div align="center">
<img src=resources/logo.svg width="40%"/>
</div>
<p align="center">
    ğŸ‘‹ åŠ å…¥æˆ‘ä»¬çš„ <a href="resources/WECHAT.md" target="_blank">å¾®ä¿¡</a> å’Œ <a href="https://discord.com/invite/8cnQKdAprg" target="_blank">Discord</a> ç¤¾åŒºã€‚
    <br>
    ğŸ“– æŸ¥çœ‹ GLM-4.1V-9B-Thinking <a href="https://arxiv.org/abs/2507.01006" target="_blank">è®ºæ–‡</a> ã€‚
    <br>
    ğŸ’¡ ç«‹å³åœ¨çº¿ä½“éªŒ <a href="https://huggingface.co/spaces/THUDM/GLM-4.1V-9B-Thinking-API-Demo" target="_blank">Hugging Face</a> æˆ– <a href="https://modelscope.cn/studios/ZhipuAI/GLM-4.1V-9B-Thinking-Demo" target="_blank">ModelScope</a> ä¸Šçš„ GLM-4.1V-9B-Thinkingã€‚
    <br>
    ğŸ“ åœ¨ <a href="https://www.bigmodel.cn/dev/api/visual-reasoning-model/GLM-4.1V-Thinking">æ™ºè°±å¤§æ¨¡å‹å¼€æ”¾å¹³å°</a> ä½¿ç”¨ GLM-4.1V-9B-Thinking çš„APIæœåŠ¡ã€‚
</p>

## æ¨¡å‹ä»‹ç»

è§†è§‰è¯­è¨€å¤§æ¨¡å‹ï¼ˆVLMï¼‰å·²ç»æˆä¸ºæ™ºèƒ½ç³»ç»Ÿçš„å…³é”®åŸºçŸ³ã€‚éšç€çœŸå®ä¸–ç•Œçš„æ™ºèƒ½ä»»åŠ¡è¶Šæ¥è¶Šå¤æ‚ï¼ŒVLMæ¨¡å‹ä¹ŸäºŸéœ€åœ¨åŸºæœ¬çš„å¤šæ¨¡æ€æ„ŸçŸ¥ä¹‹å¤–ï¼Œ
é€æ¸å¢å¼ºå¤æ‚ä»»åŠ¡ä¸­çš„æ¨ç†èƒ½åŠ›ï¼Œæå‡è‡ªèº«çš„å‡†ç¡®æ€§ã€å…¨é¢æ€§å’Œæ™ºèƒ½åŒ–ç¨‹åº¦ï¼Œä½¿å¾—å¤æ‚é—®é¢˜è§£å†³ã€é•¿ä¸Šä¸‹æ–‡ç†è§£ã€å¤šæ¨¡æ€æ™ºèƒ½ä½“ç­‰æ™ºèƒ½ä»»åŠ¡æˆä¸ºå¯èƒ½ã€‚

åŸºäº [GLM-4-9B-0414](https://github.com/THUDM/GLM-4) åŸºåº§æ¨¡å‹ï¼Œæˆ‘ä»¬æ¨å‡ºæ–°ç‰ˆVLMå¼€æºæ¨¡å‹ **GLM-4.1V-9B-Thinking**
ï¼Œå¼•å…¥æ€è€ƒèŒƒå¼ï¼Œé€šè¿‡è¯¾ç¨‹é‡‡æ ·å¼ºåŒ–å­¦ä¹  RLCSï¼ˆReinforcement Learning with Curriculum Samplingï¼‰å…¨é¢æå‡æ¨¡å‹èƒ½åŠ›ï¼Œ
è¾¾åˆ° 10B å‚æ•°çº§åˆ«çš„è§†è§‰è¯­è¨€æ¨¡å‹çš„æœ€å¼ºæ€§èƒ½ï¼Œåœ¨18ä¸ªæ¦œå•ä»»åŠ¡ä¸­æŒå¹³ç”šè‡³è¶…è¿‡8å€å‚æ•°é‡çš„ Qwen-2.5-VL-72Bã€‚
æˆ‘ä»¬åŒæ­¥å¼€æºåŸºåº§æ¨¡å‹ **GLM-4.1V-9B-Base**ï¼Œå¸Œæœ›èƒ½å¤Ÿå¸®åŠ©æ›´å¤šç ”ç©¶è€…æ¢ç´¢è§†è§‰è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›è¾¹ç•Œã€‚

![rl](resources/rl.jpeg)

ä¸ä¸Šä¸€ä»£çš„ CogVLM2 åŠ GLM-4V ç³»åˆ—æ¨¡å‹ç›¸æ¯”ï¼Œ**GLM-4.1V-Thinking** æœ‰å¦‚ä¸‹æ”¹è¿›ï¼š

1. ç³»åˆ—ä¸­é¦–ä¸ªæ¨ç†æ¨¡å‹ï¼Œä¸ä»…ä»…åœç•™åœ¨æ•°å­¦é¢†åŸŸï¼Œåœ¨å¤šä¸ªå­é¢†åŸŸå‡è¾¾åˆ°ä¸–ç•Œå‰åˆ—çš„æ°´å¹³ã€‚
2. æ”¯æŒ **64k** ä¸Šä¸‹é•¿åº¦ã€‚
3. æ”¯æŒ**ä»»æ„é•¿å®½æ¯”**å’Œé«˜è¾¾ **4k** çš„å›¾åƒåˆ†è¾¨ç‡ã€‚
4. æä¾›æ”¯æŒ**ä¸­è‹±æ–‡åŒè¯­**çš„å¼€æºæ¨¡å‹ç‰ˆæœ¬ã€‚

## æ¨¡å‹ä¿¡æ¯

### æ¨¡å‹ä¸‹è½½åœ°å€

| æ¨¡å‹                   | ä¸‹è½½åœ°å€                                                                                                                                               | æ¨¡å‹ç±»å‹ |
|----------------------|----------------------------------------------------------------------------------------------------------------------------------------------------|------|
| GLM-4.1V-9B-Thinking | [ğŸ¤—Hugging Face](https://huggingface.co/THUDM/GLM-4.1V-9B-Thinking)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.1V-9B-Thinking) | æ¨ç†æ¨¡å‹ |
| GLM-4.1V-9B-Base     | [ğŸ¤—Hugging Face](https://huggingface.co/THUDM/GLM-4.1V-9B-Base)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.1V-9B-Base)         | åŸºåº§æ¨¡å‹ |

æ¨¡å‹ç®—æ³•ä»£ç å¯ä»¥æŸ¥çœ‹ [transformers](https://github.com/huggingface/transformers/tree/main/src/transformers/models/glm4v)
çš„å®Œæ•´å®ç°ã€‚

### è¿è¡Œè¦æ±‚

#### æ¨ç†

| è®¾å¤‡ï¼ˆå•å¡ï¼‰      | æ¡†æ¶           | æœ€ä½æ˜¾å­˜å ç”¨ | é€Ÿåº¦                 | ç²¾åº¦   |
|-------------|--------------|--------|--------------------|------|
| NVIDIA A100 | transformers | 22GB   | 14 - 22 Tokens / s | BF16 |
| NVIDIA A100 | vLLM         | 22GB   | 60 - 70 Tokens / s | BF16 |

#### å¾®è°ƒ

è¯¥éƒ¨åˆ†æ•°æ®ä½¿ç”¨ [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory) æä¾›çš„å›¾ç‰‡å¾®è°ƒæ–¹æ¡ˆè¿›è¡Œæµ‹è¯•ã€‚

| è®¾å¤‡(é›†ç¾¤)      | ç­–ç•¥         | æœ€ä½æ˜¾å­˜å ç”¨ / éœ€è¦å¡æ•° | æ‰¹å¤§å° (per GPUs) | å†»ç»“æƒ…å†µ   |
|-------------|------------|---------------|----------------|--------|
| NVIDIA A100 | LORA       | 21GB / 1å¡     | 1              | å†»ç»“ VIT |
| NVIDIA A100 | FULL ZERO2 | 280GB / 4å¡    | 1              | å†»ç»“ VIT |
| NVIDIA A100 | FULL ZERO3 | 192GB  / 4å¡   | 1              | å†»ç»“ VIT |
| NVIDIA A100 | FULL ZERO2 | 304GB  / 4å¡   | 1              | ä¸å†»ç»“    |
| NVIDIA A100 | FULL ZERO3 | 210GB  / 4å¡   | 1              | ä¸å†»ç»“    |

> ä½¿ç”¨ Zero2 å¾®è°ƒå¯èƒ½å‡ºç° Loss ä¸º 0 çš„æƒ…å†µï¼Œå»ºè®®ä½¿ç”¨ Zero3 è¿›è¡Œå¾®è°ƒã€‚

## æ¦œå•ä¿¡æ¯

GLM-4.1V-9B-Thinking é€šè¿‡å¼•å…¥ã€Œæ€ç»´é“¾ã€ï¼ˆChain-of-Thoughtï¼‰æ¨ç†æœºåˆ¶ï¼Œåœ¨å›ç­”å‡†ç¡®æ€§ã€å†…å®¹ä¸°å¯Œåº¦ä¸å¯è§£é‡Šæ€§æ–¹é¢ï¼Œ
å…¨é¢è¶…è¶Šä¼ ç»Ÿçš„éæ¨ç†å¼è§†è§‰æ¨¡å‹ã€‚åœ¨28é¡¹è¯„æµ‹ä»»åŠ¡ä¸­æœ‰23é¡¹è¾¾åˆ°10Bçº§åˆ«æ¨¡å‹æœ€ä½³ï¼Œç”šè‡³æœ‰18é¡¹ä»»åŠ¡è¶…è¿‡8å€å‚æ•°é‡çš„Qwen-2.5-VL-72Bã€‚

![bench](resources/bench.jpeg)

## æ¨¡å‹æ¨ç†

æ¨¡å‹æ¨ç†ä»£ç å‡åœ¨ `inference` æ–‡ä»¶å¤¹ä¸­ï¼ŒåŒ…å«äº†:

+ `trans_infer_cli.py`: ä½¿ç”¨`transformers`åº“ä½œä¸ºæ¨ç†åç«¯çš„å‘½ä»¤è¡Œäº¤äº’è„šæœ¬ã€‚ä½ å¯ä»¥ä½¿ç”¨å®ƒè¿›è¡Œè¿ç»­å¯¹è¯ã€‚
+ `trans_infer_gradio.py`: ä½¿ç”¨`transformers`åº“ä½œä¸ºæ¨ç†åæ®µçš„ Gradio ç•Œé¢è„šæœ¬ï¼Œæ­å»ºä¸€ä¸ªå¯ä»¥ç›´æ¥ä½¿ç”¨çš„ Web
  ç•Œé¢ï¼Œæ”¯æŒå›¾ç‰‡ï¼Œè§†é¢‘ï¼ŒPDFï¼ŒPPTç­‰å¤šæ¨¡æ€è¾“å…¥ã€‚
+ ä½¿ç”¨`vllm`ç›´æ¥æ‹‰èµ·`OpenAI`æ ¼å¼çš„APIæœåŠ¡ã€‚å¹¶åœ¨`vllm_api_request.py`ä¸­æä¾›äº†ä¸€ä¸ªç®€å•çš„è¯·æ±‚ç¤ºä¾‹ã€‚

    ```shell
  vllm serve THUDM/GLM-4.1V-9B-Thinking --limit-mm-per-prompt '{"image":32}'   --allowed-local-media-path /
    ```

  + `limit-mm-per-prompt`è‹¥ä¸æŒ‡å®šï¼Œåªæ”¯æŒ1å¼ å›¾ç‰‡ã€‚æ¨¡å‹æ”¯æŒæœ€å¤š1ä¸ªè§†é¢‘æˆ–300å¼ å›¾ç‰‡è¾“å…¥ï¼Œä¸æ”¯æŒå›¾ç‰‡å’Œè§†é¢‘åŒæ—¶è¾“å…¥ã€‚
  + `allowed-local-media-path` éœ€è¦æŒ‡å®šå…è®¸è®¿é—®å¤šæ¨¡æ€å›¾ç‰‡çš„è·¯å¾„ã€‚

+ `trans_infer_bench`ï¼šç”¨äºå­¦æœ¯å¤ç°çš„æ¨ç†è„šæœ¬ï¼Œæ”¯æŒ`GLM-4.1V-9B-Thinking`æ¨¡å‹ã€‚å…¶æ ¸å¿ƒåœ¨äº
  + æŒ‡å®šäº†ä¸­æ–­æ€è€ƒçš„é•¿åº¦ï¼Œå½“æ€è€ƒé•¿åº¦è¶…è¿‡`8192`æ—¶ï¼Œå¼ºåˆ¶ä¸­æ–­æ€è€ƒå¹¶è¡¥ä¸Š`</think><answer>`
    å†æ¬¡å‘èµ·è¯·æ±‚ï¼Œè®©æ¨¡å‹ç›´æ¥è¾“å‡ºç­”æ¡ˆã€‚è¯¥ä¾‹å­ä¸­ä½¿ç”¨çš„ä¸€ä¸ªè§†é¢‘ä½œä¸ºè¾“å…¥çš„æµ‹è¯•çš„ä¾‹å­ã€‚å…¶ä»–æƒ…å†µéœ€è‡ªè¡Œä¿®æ”¹ã€‚
  + è¯¥æ–¹æ¡ˆä»…æä¾› `transformers` ç‰ˆæœ¬ï¼ŒvLLMç‰ˆæœ¬éœ€è¦è‡ªè¡Œæ ¹æ®è¯¥é€»è¾‘ä¿®æ”¹æ–¹æ¡ˆã€‚

+ `vllm_request_gui_agent.py`: è¯¥è„šæœ¬å±•ç°äº†ç”¨äº GUI Agentæ—¶å¯¹äºæ¨¡å‹è¿”å›çš„å¤„ç†å’Œæ„å»ºæç¤ºè¯æ–¹æ¡ˆ,
  åŒ…å«æ‰‹æœºï¼Œç”µè„‘å’Œç½‘é¡µç«¯çš„ç­–ç•¥ï¼Œå¯é›†æˆåˆ°æ‚¨çš„åº”ç”¨æ¡†æ¶ã€‚GUI Agentè¯¦ç»†æ–‡æ¡£è¯·æŸ¥çœ‹[è¿™é‡Œ](resources/agent_zh.md)

+ ä½¿ç”¨ Ascend NPU è®¾å¤‡æ¨ç†ï¼Œå¯æŸ¥çœ‹ [è¿™é‡Œ](https://gitee.com/ascend/MindSpeed-MM/tree/master/examples/glm4.1v/README.md)

## æ¨¡å‹å¾®è°ƒ

[LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory) å·²ç»æ”¯æŒæœ¬æ¨¡å‹çš„å¾®è°ƒã€‚ä»¥ä¸‹æ˜¯æ„å»ºæ•°æ®é›†çš„è¯´æ˜ï¼Œè¿™æ˜¯ä¸€ä¸ªä½¿ç”¨äº†ä¸¤å¼ å›¾ç‰‡çš„æ•°æ®é›†ã€‚ä½ éœ€è¦å°†æ•°æ®é›†æ•´ç†ä¸º
`finetune.json`

```json
[
  {
    "messages": [
      {
        "content": "<image>Who are they?",
        "role": "user"
      },
      {
        "content": "<think>\nUser ask me to observe the image and get the answer. I Know they are Kane and Gretzka from Bayern Munich.</think>\n<answer>They're Kane and Gretzka from Bayern Munich.</answer>",
        "role": "assistant"
      },
      {
        "content": "<image>What are they doing?",
        "role": "user"
      },
      {
        "content": "<think>\nI need to observe what this people are doing. Oh, They are celebrating on the soccer field.</think>\n<answer>They are celebrating on the soccer field.</answer>",
        "role": "assistant"
      }
    ],
    "images": [
      "mllm_demo_data/1.jpg",
      "mllm_demo_data/2.jpg"
    ]
  }
]
```

1. `<think> XXX </think>` ä¸­çš„éƒ¨åˆ†ä¸ä¼šè¢«å­˜æ”¾ä¸ºå†å²è®°å½•å’Œå¾®è°ƒã€‚
2. `<image>` æ ‡ç­¾ä¼šè¢«æ›¿æ¢æˆå›¾ç‰‡ä¿¡æ¯ã€‚

æ¥ç€ï¼Œå³å¯æŒ‰ç…§ LLaMA-Factory çš„å¾®è°ƒæ–¹å¼è¿›è¡Œå¾®è°ƒã€‚

## æ¨¡å‹åè®®

+ æœ¬ä»“åº“ä»£ç éµå¾ª[Apache License 2.0](LICENSE)åè®®ã€‚
+ GLM-4.1V-9B-Thinking å’Œ GLM-4.1V-9B-Base æ¨¡å‹å‡é‡‡ç”¨ MITåè®®ã€‚

## å¼•ç”¨è®ºæ–‡

å¦‚æœæ‚¨ä½¿ç”¨äº†æœ¬æ¨¡å‹ï¼Œè¯·å¼•ç”¨ä»¥ä¸‹è®ºæ–‡ï¼š

```bibtex
@misc{vteam2025glm41vthinkingversatilemultimodalreasoning,
      title={GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning}, 
      author={GLM-V Team and Wenyi Hong and Wenmeng Yu and Xiaotao Gu and Guo Wang and Guobing Gan and Haomiao Tang and Jiale Cheng and Ji Qi and Junhui Ji and Lihang Pan and Shuaiqi Duan and Weihan Wang and Yan Wang and Yean Cheng and Zehai He and Zhe Su and Zhen Yang and Ziyang Pan and Aohan Zeng and Baoxu Wang and Boyan Shi and Changyu Pang and Chenhui Zhang and Da Yin and Fan Yang and Guoqing Chen and Jiazheng Xu and Jiali Chen and Jing Chen and Jinhao Chen and Jinghao Lin and Jinjiang Wang and Junjie Chen and Leqi Lei and Letian Gong and Leyi Pan and Mingzhi Zhang and Qinkai Zheng and Sheng Yang and Shi Zhong and Shiyu Huang and Shuyuan Zhao and Siyan Xue and Shangqin Tu and Shengbiao Meng and Tianshu Zhang and Tianwei Luo and Tianxiang Hao and Wenkai Li and Wei Jia and Xin Lyu and Xuancheng Huang and Yanling Wang and Yadong Xue and Yanfeng Wang and Yifan An and Yifan Du and Yiming Shi and Yiheng Huang and Yilin Niu and Yuan Wang and Yuanchang Yue and Yuchen Li and Yutao Zhang and Yuxuan Zhang and Zhanxiao Du and Zhenyu Hou and Zhao Xue and Zhengxiao Du and Zihan Wang and Peng Zhang and Debing Liu and Bin Xu and Juanzi Li and Minlie Huang and Yuxiao Dong and Jie Tang},
      year={2025},
      eprint={2507.01006},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2507.01006}, 
}
```
