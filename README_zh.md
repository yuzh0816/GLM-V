# GLM-4.1V-Thinking

[Read this in English.](./README.md)

<div align="center">
<img src=resources/logo.svg width="40%"/>
</div>
<p align="center">
    ğŸ‘‹ åŠ å…¥æˆ‘ä»¬çš„ <a href="resources/WECHAT.md" target="_blank">å¾®ä¿¡</a> å’Œ <a href="https://discord.com/invite/8cnQKdAprg" target="_blank">Discord</a> ç¤¾åŒºã€‚
    <br>
    ğŸ’¡ åœ¨çº¿ä½“éªŒ <a href="https://huggingface.co/spaces/THUDM/GLM-4.1V-9B-Thinking-Demo" target="_blank">GLM-4.1V-9B-Thinking</a>
    <br>
    ğŸ“ åœ¨ <a href="https://open.bigmodel.cn/?utm_campaign=open&_channel_track_key=OWTVNma9">å¼€æ”¾å¹³å°</a> ä½¿ç”¨ GLM-4.1V-9B-Thinking çš„ APIæœåŠ¡ã€‚
</p>

## Demoå±•ç¤º

## æ¨¡å‹ä»‹ç»

åŸºäº [GLM-4-9B-0414](https://github.com/THUDM/GLM-4) åŸºåº§æ¨¡å‹ï¼Œæˆ‘ä»¬æ¨å‡ºæ–°ç‰ˆVLMå¼€æºæ¨¡å‹**GLM-4.1V-Thinking**
ï¼Œæ¢ç´¢æ¨ç†æ¨¡å‹åœ¨è§†è§‰è¯­è¨€æ¨¡å‹çš„å¤šä¸ªé¢†åŸŸä¸­çš„ä¸Šé™ã€‚ä¸ä¸Šä¸€ä»£çš„ CogVLM2 åŠ GLM-4V ç³»åˆ—æ¨¡å‹ç›¸æ¯”ï¼Œ**GLM-4.1V-Thinking** æœ‰å¦‚ä¸‹æ”¹è¿›ï¼š

1. ç³»åˆ—ä¸­é¦–ä¸ªæ¨ç†æ¨¡å‹ï¼Œä¸ä»…ä»…åœç•™åœ¨æ•°å­¦é¢†åŸŸï¼Œåœ¨å¤šä¸ªå­é¢†åŸŸå‡è¾¾åˆ°ä¸–ç•Œå‰åˆ—çš„æ°´å¹³ã€‚
2. æ”¯æŒ **8K** æ–‡æœ¬é•¿åº¦ã€‚
3. æ”¯æŒé«˜è¾¾ **1344 * 1344** çš„å›¾åƒåˆ†è¾¨ç‡ã€‚
4. æä¾›æ”¯æŒ**ä¸­è‹±æ–‡åŒè¯­**çš„å¼€æºæ¨¡å‹ç‰ˆæœ¬ã€‚

## æ¨¡å‹ä¿¡æ¯

### æ¨¡å‹ä¸‹è½½åœ°å€

| æ¨¡å‹                   | ä¸‹è½½åœ°å€                                                                                                                                                                                                                          | æ¨¡å‹ç±»å‹ |
|----------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------|
| GLM-4.1V-9B-Thinking | [ğŸ¤—Hugging Face](https://huggingface.co/THUDM/GLM-4.1V-9B-Thinking)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.1V-9B-Thinking)<br> [ğŸ§© Modelers](https://modelers.cn/models/zhipuai/GLM-4.1V-9B-Thinking) | æ¨ç†æ¨¡å‹ |
| GLM-4.1V-9B-Base     | [ğŸ¤—Hugging Face](https://huggingface.co/THUDM/GLM-4.1V-9B-Base)<br> [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-4.1V-9B-Base)<br> [ğŸ§© Modelers](https://modelers.cn/models/zhipuai/GLM-4.1V-9B-Base)             | åŸºåº§æ¨¡å‹ |

æ¨¡å‹ç®—æ³•ä»£ç å¯ä»¥æŸ¥çœ‹ [transformers](https://github.com/huggingface/transformers/tree/main/src/transformers/models/glm4v)
çš„å®Œæ•´å®ç°ã€‚

### è¿è¡Œè¦æ±‚

#### æ¨ç†

| è®¾å¤‡          | æ¡†æ¶           | æœ€ä½æ˜¾å­˜å ç”¨ | é€Ÿåº¦                 | ç²¾åº¦   |
|-------------|--------------|--------|--------------------|------|
| NVIDIA A100 | transformers | 22GB   | 14 - 22 Tokens / s | BF16 |
| NVIDIA A100 | vLLM         | 25GB   | 38 - 60 Tokens / s | BF16 |

#### å¾®è°ƒ

| è®¾å¤‡          | ç­–ç•¥         | æœ€ä½æ˜¾å­˜å ç”¨ | Batch Size | ç²¾åº¦   | å†»ç»“æƒ…å†µ   |
|-------------|------------|--------|------------|------|--------|
| NVIDIA A100 | LORA       | 21GB   | 1          | BF16 | å†»ç»“ VIT |
| NVIDIA A100 | FULL ZERO2 | 280GB  | 1          | BF16 | å†»ç»“ VIT |
| NVIDIA A100 | FULL ZERO3 | 192GB  | 1          | BF16 | å†»ç»“ VIT |
| NVIDIA A100 | FULL ZERO2 | 304GB  | 1          | BF16 | ä¸å†»ç»“    |
| NVIDIA A100 | FULL ZERO3 | 210GB  | 1          | BF16 | ä¸å†»ç»“    |

> ä½¿ç”¨ Zero2 å¾®è°ƒå¯èƒ½å‡ºç° Loss ä¸º 0 çš„æƒ…å†µï¼Œå»ºè®®ä½¿ç”¨ Zero3 è¿›è¡Œå¾®è°ƒã€‚

## æ¦œå•ä¿¡æ¯

## æ¨¡å‹æ¨ç†

æ¨¡å‹æ¨ç†ä»£ç å‡åœ¨ `inference` æ–‡ä»¶å¤¹ä¸­ï¼ŒåŒ…å«äº†:

+ `trans_infer_cli.py`: ä½¿ç”¨`transformers`åº“ä½œä¸ºæ¨ç†åç«¯çš„å‘½ä»¤è¡Œäº¤äº’è„šæœ¬ã€‚ä½ å¯ä»¥ä½¿ç”¨å®ƒè¿›è¡Œè¿ç»­å¯¹è¯ã€‚
+ `trans_infer_gradio.py`: ä½¿ç”¨`transformers`åº“ä½œä¸ºæ¨ç†åæ®µçš„ Gradio ç•Œé¢è„šæœ¬ï¼Œæ­å»ºä¸€ä¸ªå¯ä»¥ç›´æ¥ä½¿ç”¨çš„ Web
  ç•Œé¢ï¼Œæ”¯æŒå›¾ç‰‡ï¼Œè§†é¢‘ï¼ŒPDFï¼ŒPPTç­‰å¤šæ¨¡æ€è¾“å…¥ã€‚
+ ä½¿ç”¨`vllm`ç›´æ¥æ‹‰èµ·`OpenAI`æ ¼å¼çš„APIæœåŠ¡ã€‚å¹¶åœ¨`vllm_api_request.py`ä¸­æä¾›äº†ä¸€ä¸ªç®€å•çš„è¯·æ±‚ç¤ºä¾‹ã€‚

```shell
vllm serve THUDM/GLM-4.1V-9B-Thinking  --allowed-local-media-path /
```

+ `trans_infer_bench`ï¼šç”¨äºå­¦æœ¯å¤ç°çš„æ¨ç†è„šæœ¬ï¼Œæ”¯æŒ`GLM-4.1V-9B-Thinking`æ¨¡å‹ã€‚å…¶æ ¸å¿ƒåœ¨äº
  + æŒ‡å®šäº†ä¸­æ–­æ€è€ƒçš„é•¿åº¦ï¼Œå½“æ€è€ƒé•¿åº¦è¶…è¿‡`8192`æ—¶ï¼Œå¼ºåˆ¶ä¸­æ–­æ€è€ƒå¹¶è¡¥ä¸Š`</think>\n<answer>`å†æ¬¡å‘èµ·è¯·æ±‚ï¼Œè®©æ¨¡å‹ç›´æ¥è¾“å‡ºç­”æ¡ˆã€‚
  + è¯¥æ–¹æ¡ˆä»…æä¾› `transformers` ç‰ˆæœ¬ï¼ŒvLLMç‰ˆæœ¬éœ€è¦è‡ªè¡Œæ ¹æ®è¯¥é€»è¾‘ä¿®æ”¹æ–¹æ¡ˆã€‚
  + è¯¥ä¾‹å­ä¸­ä½¿ç”¨çš„ä¸€ä¸ªè§†é¢‘ä½œä¸ºè¾“å…¥çš„æµ‹è¯•çš„ä¾‹å­ã€‚

## æ¨¡å‹å¾®è°ƒ

[LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory) å·²ç»æ”¯æŒæœ¬æ¨¡å‹çš„å¾®è°ƒã€‚ä»¥ä¸‹æ˜¯æ„å»ºæ•°æ®é›†çš„è¯´æ˜ï¼Œè¿™æ˜¯ä¸€ä¸ªä½¿ç”¨äº†ä¸¤å¼ å›¾ç‰‡çš„æ•°æ®é›†ã€‚ä½ éœ€è¦å°†æ•°æ®é›†æ•´ç†ä¸º
`finetune.json`

```json
[
  {
    "messages": [
      {
        "content": "<image>Who are they?",
        "role": "user"
      },
      {
        "content": "<think>\nUser ask me to observe the image and get the answer. I Know they are Kane and Gretzka from Bayern Munich.</think>\n<answer>They're Kane and Gretzka from Bayern Munich.</answer>",
        "role": "assistant"
      },
      {
        "content": "<image>What are they doing?",
        "role": "user"
      },
      {
        "content": "<think>\nI need to observe what this people are doing. Oh, They are celebrating on the soccer field.</think>\n<answer>They are celebrating on the soccer field.</answer>",
        "role": "assistant"
      }
    ],
    "images": [
      "mllm_demo_data/1.jpg",
      "mllm_demo_data/2.jpg"
    ]
  }
]
```

1. `<think> XXX </think>` ä¸­çš„éƒ¨åˆ†ä¸ä¼šè¢«å­˜æ”¾ä¸ºå†å²è®°å½•å’Œå¾®è°ƒã€‚
2. `<image>` æ ‡ç­¾ä¼šè¢«æ›¿æ¢æˆå›¾ç‰‡ä¿¡æ¯ã€‚

æ¥ç€ï¼Œå³å¯æŒ‰ç…§ LLaMA-Factory çš„å¾®è°ƒæ–¹å¼è¿›è¡Œå¾®è°ƒã€‚

## æ¨¡å‹åè®®

+ æœ¬ä»“åº“ä»£ç éµå¾ª[Apache License 2.0](LICENSE) åè®®ã€‚
+ GLM-4.1V-9B-Thinking å’Œ GLM-4.1V-9B-Base æ¨¡å‹å‡é‡‡ç”¨ MITåè®®ã€‚
